
import { GoogleGenAI } from "@google/genai";

const API_KEY = process.env.API_KEY || "";

export const mergeImagesWithAI = async (
  youngImageBase64: string,
  oldImageBase64: string,
  promptTemplate: string
): Promise<string> => {
  if (!API_KEY) {
    throw new Error("API Key is missing. Please ensure it is configured.");
  }

  const ai = new GoogleGenAI({ apiKey: API_KEY });
  
  // We use gemini-2.5-flash-image for general image generation and editing
  const model = 'gemini-2.5-flash-image';

  const parts = [
    {
      inlineData: {
        data: youngImageBase64.split(',')[1],
        mimeType: 'image/png',
      },
    },
    {
      inlineData: {
        data: oldImageBase64.split(',')[1],
        mimeType: 'image/png',
      },
    },
    {
      text: `Combine these two people into a single photograph. Person 1 is the younger version, Person 2 is the older version. 
      ${promptTemplate}
      Ensure both people are clearly visible and looking natural together. Maintain their facial features as closely as possible.`
    }
  ];

  try {
    const response = await ai.models.generateContent({
      model: model,
      contents: { parts },
      config: {
        imageConfig: {
          aspectRatio: "3:4"
        }
      }
    });

    if (!response.candidates || response.candidates.length === 0) {
      throw new Error("No image generated by the AI.");
    }

    // Iterate through parts to find the image
    for (const part of response.candidates[0].content.parts) {
      if (part.inlineData) {
        return `data:image/png;base64,${part.inlineData.data}`;
      }
    }

    throw new Error("The AI returned a response but no image data was found.");
  } catch (error) {
    console.error("Gemini API Error:", error);
    throw error;
  }
};
